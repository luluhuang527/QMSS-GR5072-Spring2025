{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7720b2d-914c-4fbf-99bc-82ac3f678491",
   "metadata": {},
   "source": [
    "# Modern Data Structures Homework 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c70eef4-0d39-411a-9e9b-5cffd2a05324",
   "metadata": {},
   "source": [
    "Hsin-Ju (Lulu) Huang  \n",
    "hh3105"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6707147e-4b36-43f1-a9da-e36b919fff72",
   "metadata": {},
   "source": [
    "# 1. [10 pts] Web-scrape all table data from the following webpage and build a pd.DataFrame object. Limit your final table to include columns for \"Package\", \"Item\", \"Title\", \"Rows\", and \"Cols\". Print the dimensions and first five rows of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f12c7ccd-543d-49ed-806d-a26bfe704c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: (2537, 5)\n",
      "  Package           Item                                              Title  \\\n",
      "0     AER        Affairs                   Fair's Extramarital Affairs Data   \n",
      "1     AER   ArgentinaCPI                  Consumer Price Index in Argentina   \n",
      "2     AER      BankWages                                         Bank Wages   \n",
      "3     AER  BenderlyZwick  Benderly and Zwick Data: Inflation, Growth and...   \n",
      "4     AER      BondYield                                    Bond Yield Data   \n",
      "\n",
      "    Rows  Cols  \n",
      "0  601.0   9.0  \n",
      "1   80.0   2.0  \n",
      "2  474.0   4.0  \n",
      "3   31.0   5.0  \n",
      "4   60.0   2.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://vincentarelbundock.github.io/Rdatasets/datasets.html\"\n",
    "tables = pd.read_html(url)\n",
    "df = tables[0]\n",
    "df = df[[\"Package\", \"Item\", \"Title\", \"Rows\", \"Cols\"]]\n",
    "\n",
    "print(\"Dimensions:\", df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61ad1ad-d296-4cdb-9228-e33c50f4d7e6",
   "metadata": {},
   "source": [
    "# 2. [10 pts] Web-scrape the full links to every CSV file listed in the CSV column of the web-page. Add a new column to your data frame that includes these links. Name the column \"csv_links\". Print the first five rows of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "832ddac0-d235-4fdb-bf92-1125319107a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Package           Item                                              Title  \\\n",
      "0     AER        Affairs                   Fair's Extramarital Affairs Data   \n",
      "1     AER   ArgentinaCPI                  Consumer Price Index in Argentina   \n",
      "2     AER      BankWages                                         Bank Wages   \n",
      "3     AER  BenderlyZwick  Benderly and Zwick Data: Inflation, Growth and...   \n",
      "4     AER      BondYield                                    Bond Yield Data   \n",
      "\n",
      "    Rows  Cols                                          csv_links  \n",
      "0  601.0   9.0                                               None  \n",
      "1   80.0   2.0  https://vincentarelbundock.github.io/Rdatasets...  \n",
      "2  474.0   4.0  https://vincentarelbundock.github.io/Rdatasets...  \n",
      "3   31.0   5.0  https://vincentarelbundock.github.io/Rdatasets...  \n",
      "4   60.0   2.0  https://vincentarelbundock.github.io/Rdatasets...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lulu\\AppData\\Local\\Temp\\ipykernel_24696\\187735225.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_limited[\"csv_links\"] = csv_links\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the dataset webpage\n",
    "url = \"https://vincentarelbundock.github.io/Rdatasets/datasets.html\"\n",
    "\n",
    "# Download the HTML content\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Step 1: Read the main table into a DataFrame using pandas\n",
    "df_full = pd.read_html(url)[0]\n",
    "\n",
    "# Keep only the columns we need\n",
    "df_limited = df_full[[\"Package\", \"Item\", \"Title\", \"Rows\", \"Cols\"]]\n",
    "\n",
    "# Step 2: Extract CSV links using BeautifulSoup\n",
    "base_url = \"https://vincentarelbundock.github.io/Rdatasets/\"\n",
    "csv_links = []\n",
    "\n",
    "# Loop through each table row (skipping the header row)\n",
    "for tr in soup.find_all(\"tr\")[1:]:\n",
    "    # Find all the table data cells in the row\n",
    "    tds = tr.find_all(\"td\")\n",
    "    if len(tds) < 2:\n",
    "        # If the row is malformed (too few cells), append None to keep alignment\n",
    "        csv_links.append(None)\n",
    "        continue\n",
    "\n",
    "    # Get the second-to-last cell, which should contain the CSV link\n",
    "    csv_cell = tds[-2]\n",
    "    a_tag = csv_cell.find(\"a\")\n",
    "    href = a_tag.get(\"href\") if a_tag else None\n",
    "\n",
    "    if href:\n",
    "        # If the href is a full URL, use it; otherwise, prepend the base URL\n",
    "        full_link = href if href.startswith(\"http\") else base_url + href\n",
    "    else:\n",
    "        full_link = None\n",
    "\n",
    "    csv_links.append(full_link)\n",
    "\n",
    "# Step 3: Add the CSV links to the DataFrame\n",
    "df_limited[\"csv_links\"] = csv_links\n",
    "\n",
    "# Step 4: Show the first five rows to confirm\n",
    "print(df_limited.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3134ba8-2637-42fe-b2ec-fde571323bd7",
   "metadata": {},
   "source": [
    "# 3. [5 pts] Search the \"Title\" column to return the row of data with the title \"Violent Crime Rates by US State\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c540cdd-0949-452f-82bb-6e93455903b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching row:\n",
      "      Package       Item                            Title  Rows  Cols  \\\n",
      "543  datasets  USArrests  Violent Crime Rates by US State  50.0   4.0   \n",
      "\n",
      "                                             csv_links  \n",
      "543  https://vincentarelbundock.github.io/Rdatasets...  \n",
      "\n",
      "CSV link: https://vincentarelbundock.github.io/Rdatasets/csv/datasets/USAccDeaths.csv\n"
     ]
    }
   ],
   "source": [
    "# Question 3 [5 pts]\n",
    "\n",
    "# Case-insensitive search to find the correct row with the violent crime dataset\n",
    "crime_row = df_limited[df_limited[\"Title\"].str.contains(\n",
    "    \"violent crime rates by us state\", case=False, na=False)]\n",
    "\n",
    "print(\"Matching row:\")\n",
    "print(crime_row)\n",
    "\n",
    "# Display the CSV link separately to confirm it's correct\n",
    "csv_link = crime_row[\"csv_links\"].values[0]\n",
    "print(\"\\nCSV link:\", csv_link)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e3c74-7847-47c0-b46d-44c43c5679cc",
   "metadata": {},
   "source": [
    "# 4. [10 pts] Import the csv file for the dataset identified in #3 using the full link listed in the \"csv_links\" column for this dataset. Create a new variable called \"violent_crime\" that adds together data for all columns in the dataset that contain violent crime data (i.e.-add data from assault, murder, and rape columns together in new column called \"violent_crime\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85eb7e47-a251-4eb3-ab7c-5e32b3155204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State  Murder  Assault  UrbanPop  Rape  violent_crime\n",
      "0     Alabama    13.2      236        58  21.2          270.4\n",
      "1      Alaska    10.0      263        48  44.5          317.5\n",
      "2     Arizona     8.1      294        80  31.0          333.1\n",
      "3    Arkansas     8.8      190        50  19.5          218.3\n",
      "4  California     9.0      276        91  40.6          325.6\n"
     ]
    }
   ],
   "source": [
    "# Use the known correct CSV link directly\n",
    "vc_link = \"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/USArrests.csv\"\n",
    "\n",
    "# Read the CSV file using the first column (state names) as the index\n",
    "df_crime = pd.read_csv(vc_link, index_col=0)\n",
    "\n",
    "# Rename the index to \"State\" and reset it to make it a column\n",
    "df_crime.index.name = \"State\"\n",
    "df_crime = df_crime.reset_index()\n",
    "\n",
    "# Create the 'violent_crime' variable by summing Murder, Assault, and Rape\n",
    "df_crime['violent_crime'] = (\n",
    "    df_crime['Murder'] +\n",
    "    df_crime['Assault'] +\n",
    "    df_crime['Rape']\n",
    ")\n",
    "\n",
    "# Display the first few rows to confirm\n",
    "print(df_crime.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fa151a-a3fe-4d6e-abe0-ec0bb5be9e08",
   "metadata": {},
   "source": [
    "# 5. [10 pts] Merge all the data from the states.csv data set (found in the data folder of this HW6 directory) with your dataset to your Violent Crime Rates data frame. Print the first five lines of your new dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a9843ac-8908-4799-a273-f9226f43b606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State  Murder_x  Assault  UrbanPop  Rape  violent_crime state.abb  \\\n",
      "0     Alabama      13.2      236        58  21.2          270.4        AL   \n",
      "1      Alaska      10.0      263        48  44.5          317.5        AK   \n",
      "2     Arizona       8.1      294        80  31.0          333.1        AZ   \n",
      "3    Arkansas       8.8      190        50  19.5          218.3        AR   \n",
      "4  California       9.0      276        91  40.6          325.6        CA   \n",
      "\n",
      "   state.area  state.division state.name.1  state.region  Population  Income  \\\n",
      "0       51609               4      Alabama             2        3615    3624   \n",
      "1      589757               9       Alaska             4         365    6315   \n",
      "2      113909               8      Arizona             4        2212    4530   \n",
      "3       53104               5     Arkansas             2        2110    3378   \n",
      "4      158693               9   California             4       21198    5114   \n",
      "\n",
      "   Illiteracy  Life.Exp  Murder_y  HS.Grad  Frost    Area  \n",
      "0         2.1     69.05      15.1     41.3     20   50708  \n",
      "1         1.5     69.31      11.3     66.7    152  566432  \n",
      "2         1.8     70.55       7.8     58.1     15  113417  \n",
      "3         1.9     70.66      10.1     39.9     65   51945  \n",
      "4         1.1     71.71      10.3     62.6     20  156361  \n"
     ]
    }
   ],
   "source": [
    "# Question 5 [10 pts]\n",
    "\n",
    "# Step 1: Read the states.csv file\n",
    "states_df = pd.read_csv(\"states.csv\")\n",
    "\n",
    "# Step 2: Rename the 'state.name' column to 'State'\n",
    "states_df.rename(columns={\"state.name\": \"State\"}, inplace=True)\n",
    "\n",
    "# Step 3: Merge with df_crime on 'State'\n",
    "states_merged = df_crime.merge(states_df, on=\"State\", how=\"left\")\n",
    "\n",
    "# Step 4: Print the first five rows of the merged data\n",
    "print(states_merged.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e79f360-9f17-4e35-ade9-2f73d2d31ede",
   "metadata": {},
   "source": [
    "# 6. [5 pts] Calculate the average for each numeric column in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e8bed7fd-24d7-4acd-96dc-98235370420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of each numeric column:\n",
      "Murder_x              7.7880\n",
      "Assault             170.7600\n",
      "UrbanPop             65.5400\n",
      "Rape                 21.2320\n",
      "violent_crime       199.7800\n",
      "state.area        72367.9800\n",
      "state.division        5.2000\n",
      "state.region          2.5800\n",
      "Population         4246.4200\n",
      "Income             4435.8000\n",
      "Illiteracy            1.1700\n",
      "Life.Exp             70.8786\n",
      "Murder_y              7.3780\n",
      "HS.Grad              53.1080\n",
      "Frost               104.4600\n",
      "Area              70735.8800\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Question 6 [5 pts]\n",
    "\n",
    "# Calculate the average (mean) for each numeric column\n",
    "column_means = states_merged.mean(numeric_only=True)\n",
    "\n",
    "# Display the result\n",
    "print(\"Average of each numeric column:\")\n",
    "print(column_means)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6b4f93-bf6a-4445-b07d-1eb28d25ede0",
   "metadata": {},
   "source": [
    "# 7. [10 pts] Group the data by region and then calculate the average for each numeric column in the dataset per region. Which region had the highest population (data is from the late 1970s)? Which region had the most violent crime?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8da448d-5c95-4809-8a98-bd852f212c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average values per region:\n",
      "               Murder_x     Assault   UrbanPop       Rape  violent_crime  \\\n",
      "state.region                                                               \n",
      "1              4.700000  126.666667  70.555556  13.777778     145.144444   \n",
      "2             11.706250  220.000000  59.437500  21.162500     252.868750   \n",
      "3              5.700000  120.333333  64.416667  18.441667     144.475000   \n",
      "4              7.030769  187.230769  70.615385  29.053846     223.315385   \n",
      "\n",
      "                 state.area  state.division   Population       Income  \\\n",
      "state.region                                                            \n",
      "1              18817.000000        1.333333  5495.111111  4570.222222   \n",
      "2              56222.250000        3.750000  4208.125000  4011.937500   \n",
      "3              63794.166667        6.583333  4803.000000  4611.083333   \n",
      "4             137227.692308        8.384615  2915.307692  4702.615385   \n",
      "\n",
      "              Illiteracy   Life.Exp   Murder_y    HS.Grad       Frost  \\\n",
      "state.region                                                            \n",
      "1               1.000000  71.264444   4.722222  53.966667  132.777778   \n",
      "2               1.737500  69.706250  10.581250  44.343750   64.625000   \n",
      "3               0.700000  71.766667   5.275000  54.516667  138.833333   \n",
      "4               1.023077  71.234615   7.215385  62.000000  102.153846   \n",
      "\n",
      "                    Area  \n",
      "state.region              \n",
      "1              18141.000  \n",
      "2              54605.125  \n",
      "3              62652.000  \n",
      "4             134463.000  \n",
      "\n",
      "Region with the highest average population: 1 with population: 5495.111111111111\n",
      "Region with the highest average violent crime: 2 with violent crime: 252.86875\n"
     ]
    }
   ],
   "source": [
    "# Question 7 [10 pts]\n",
    "\n",
    "# Step 1: Group by region and calculate the mean for each numeric column\n",
    "region_means = states_merged.groupby(\"state.region\").mean(numeric_only=True)\n",
    "\n",
    "# Step 2: Display the result\n",
    "print(\"Average values per region:\")\n",
    "print(region_means)\n",
    "\n",
    "# Step 3: Identify the region with the highest average population\n",
    "max_population_region = region_means[\"Population\"].idxmax()\n",
    "max_population_value = region_means[\"Population\"].max()\n",
    "\n",
    "# Step 4: Identify the region with the highest average violent crime\n",
    "max_violent_region = region_means[\"violent_crime\"].idxmax()\n",
    "max_violent_value = region_means[\"violent_crime\"].max()\n",
    "\n",
    "print(\"\\nRegion with the highest average population:\", max_population_region,\n",
    "      \"with population:\", max_population_value)\n",
    "\n",
    "print(\"Region with the highest average violent crime:\", max_violent_region,\n",
    "      \"with violent crime:\", max_violent_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a6e7f2-ce28-4e63-bf99-25dbcafa7ba1",
   "metadata": {},
   "source": [
    "# 8. [5 pts] What SQL statement would you write to return two columns denoting income and Illiteracy in your state data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e765b0dd-d0d1-4023-9124-e861f2fb6c40",
   "metadata": {},
   "source": [
    "SELECT Income, Illiteracy\n",
    "FROM states_merged;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ff1b65-4939-4fed-803b-dc17b0b1ffa6",
   "metadata": {},
   "source": [
    "# 9. [10 pts] What SQL statement would you write to return two columns denoting income and Illiteracy in your state data and sort the data from the highest to lowest income values and limit the data to incomes at or higher than 5000?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b48334-ff19-467e-90f2-9c116b7076ed",
   "metadata": {},
   "source": [
    "SELECT Income, Illiteracy\n",
    "FROM states_merged\n",
    "WHERE Income >= 5000\n",
    "ORDER BY Income DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e20dc7f-83a9-4ea8-9978-ec27482ee807",
   "metadata": {},
   "source": [
    "# 10. [10 pts] Create a new data frame that includes two columns from your state data denoting state names and violent crimes. Spread the state names to 50 unique columns with a single row that includes the violent crime data per state. Print the first five columns of the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fed2e018-dcf8-414f-9485-30415e00d7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five columns of the new dataset:\n",
      "State          Alabama  Alaska  Arizona  Arkansas  California\n",
      "violent_crime    270.4   317.5    333.1     218.3       325.6\n"
     ]
    }
   ],
   "source": [
    "# Question 10 [10 pts]\n",
    "\n",
    "# Step 1: Create a smaller DataFrame with State and violent_crime\n",
    "crime_wide = states_merged[[\"State\", \"violent_crime\"]]\n",
    "\n",
    "# Step 2: Pivot the data so each State becomes a column\n",
    "crime_wide_pivot = crime_wide.set_index(\"State\").T\n",
    "\n",
    "# Step 3: Show the first five columns\n",
    "print(\"First five columns of the new dataset:\")\n",
    "print(crime_wide_pivot.iloc[:, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783774fe-8912-49a5-bd4c-067901e4fca4",
   "metadata": {},
   "source": [
    "# 11. [10 pts] Take the dataset from question 10 and use a function to return a dictionary with each key denoting a state and each value indicating the square root of the value for violent crimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8582bcd-8159-4060-ac65-d415dd0eca02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five states with sqrt of violent crime:\n",
      "Alabama: 16.44\n",
      "Alaska: 17.82\n",
      "Arizona: 18.25\n",
      "Arkansas: 14.77\n",
      "California: 18.04\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Question 11 [10 pts]\n",
    "\n",
    "# Step 1: Get the row with violent crime values\n",
    "violent_crime_values = crime_wide_pivot.loc[\"violent_crime\"]\n",
    "\n",
    "# Step 2: Use a dictionary comprehension to compute the square roots\n",
    "crime_sqrt_dict = {state: np.sqrt(value) for state, value in violent_crime_values.items()}\n",
    "\n",
    "# Step 3: Print the first five entries of the dictionary to check\n",
    "print(\"First five states with sqrt of violent crime:\")\n",
    "for i, (state, sqrt_value) in enumerate(crime_sqrt_dict.items()):\n",
    "    if i >= 5:\n",
    "        break\n",
    "    print(f\"{state}: {sqrt_value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598bf9df-c414-4aa9-8e5e-0130da9e04ba",
   "metadata": {},
   "source": [
    "# 12. [5 pts] Subset the list you created in question 12 to extract values for Texas and New York."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6fe1b4f9-1691-4d1e-8513-36f9e667445d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Square root of violent crime:\n",
      "Texas: 15.47\n",
      "New York: 17.06\n"
     ]
    }
   ],
   "source": [
    "# Question 12 [5 pts]\n",
    "\n",
    "# Extract the square root of violent crime values for Texas and New York\n",
    "texas_value = crime_sqrt_dict.get(\"Texas\")\n",
    "new_york_value = crime_sqrt_dict.get(\"New York\")\n",
    "\n",
    "# Print the results\n",
    "print(\"Square root of violent crime:\")\n",
    "print(f\"Texas: {texas_value:.2f}\")\n",
    "print(f\"New York: {new_york_value:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
